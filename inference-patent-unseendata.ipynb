{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98582063-6f4c-44c1-bdd3-37857f5d6063",
   "metadata": {},
   "source": [
    "## This code is used for patent draft inference on sample unseen patents with some initial inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0c343d1-039b-417b-8e22-cebe7807122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:660: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMAGE RECOGNITION TECHNOLOGY IS COMMONLY USED IN SECURITY SYSTEMS TO IDENTIFY FACES AND OBJECTS. CURRENT AI-BASED IMAGE RECOGNITION SYSTEMS ARE PRONE TO FALSE POSITIVES AND STRUGGLE IN LOW\n",
      "\n",
      "BACKGROUND\n",
      "Field: Image recognition technology is commonly used in security systems to identify faces and objects. Current AI-based image recognition systems are prone to false positives and struggle in low-light conditions, compromising security. This system includes infrared sensors and a new AI algorithm that enhances recognition accuracy\n",
      "\n",
      "SUMMARY\n",
      "Image recognition technology is commonly used in security systems to identify faces and objects. However, current AI-based image recognition systems are prone to false positives and struggle in low-light conditions, compromising security. The system includes infrared sensors and a new AI algorithm that enhances recognition accuracy in low-light environments.\n",
      "\n",
      "ABSTRACT\n",
      "\n",
      "Image recognition technology is commonly used in security systems to identify faces and objects. Current AI-based image recognition systems are prone to false positives and struggle in low-light conditions, compromising security. The system includes infrared sensors and a new AI algorithm that enhances recognition accuracy in low-light environments.\n",
      "\n",
      "CLAIMS\n",
      "\n",
      "1. An image recognition system, comprising:\n",
      "2. a. a camera system comprising a plurality of infrared sensors, wherein the camera system is configured to capture images at night or in low-light conditions; and\n",
      "3. b. an artificial intelligence (AI) processing unit configured to process the images captured by the camera system using a new AI algorithm to identify objects, wherein the new AI algorithm improves the accuracy of image recognition in low-light conditions. The image recognition system of  claim 1, wherein the new AI algorithm comprises a deep neural network (DNN) trained using a new image dataset that includes night images. 3. The image recognition system of  claim 2, wherein the DNN comprises a convolutional neural network (CNN). 4. The image recognition system of  claim 3, wherein the CNN comprises a ResNet-50 network. 5. The image recognition system of  claim 1, wherein the plurality of infrared sensors are arranged in a grid pattern. 6. 7. 8. 9. 10. 11. 12.\n",
      "\n",
      "DESCRIPTION\n",
      "\n",
      "Image recognition technology is commonly used in security systems to identify faces and objects. However, current AI-based image recognition systems are prone to false positives and struggle in low-light conditions, compromising security. We propose a novel approach that combines infrared sensors and a new AI algorithm to enhance recognition accuracy in low-light environments. By incorporating infrared sensors into the camera, our system can detect and track objects even in near-total darkness, significantly improving security and reliability.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Hugging Face Model Name\n",
    "model_name = \"beunique/Llama-3.1-8B-bnb-4bit-patent\"\n",
    "\n",
    "# Load the model and tokenizer from Hugging Face\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Ensure the model is in evaluation mode for inference\n",
    "model.eval()\n",
    "\n",
    "def generate_patent_section(instruction, input_text, max_tokens=512):\n",
    "    prompt = f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=max_tokens,\n",
    "            temperature=0.7,\n",
    "            top_k=40,\n",
    "            top_p=0.92\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    response = generated_text.split(\"### Response:\")[-1].strip()\n",
    "    return response\n",
    "\n",
    "def prepare_input(input_data):\n",
    "    return f\"\"\"Field of Invention: {input_data['field']}\n",
    "Problem to Solve: {input_data['problem_statement']}\n",
    "Related Art: {input_data['related_art']}\n",
    "Key Features: {input_data['additional_details']}\n",
    "Drawings: {input_data['drawings']}\"\"\"\n",
    "\n",
    "def format_claims(claims_text):\n",
    "    formatted_claims = []\n",
    "    seen_claims = set()\n",
    "    for claim in claims_text.split('\\n'):\n",
    "        claim = claim.strip()\n",
    "        if claim and claim.lower() not in seen_claims:\n",
    "            if not claim[0].isdigit():\n",
    "                claim = f\"{len(formatted_claims) + 1}. {claim}\"\n",
    "            formatted_claims.append(claim)\n",
    "            seen_claims.add(claim.lower())\n",
    "    return '\\n'.join(formatted_claims)\n",
    "\n",
    "def remove_duplicate_claims(claims):\n",
    "    unique_claims = []\n",
    "    seen = set()\n",
    "    for claim in claims.split('\\n'):\n",
    "        claim_text = ' '.join(claim.split()[1:])  # Remove the claim number\n",
    "        if claim_text not in seen:\n",
    "            unique_claims.append(claim)\n",
    "            seen.add(claim_text)\n",
    "    return '\\n'.join(unique_claims)\n",
    "\n",
    "\n",
    "def remove_repetitive_sentences(text, similarity_threshold=0.8):\n",
    "    # Load a pre-trained sentence transformer model\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    \n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    \n",
    "    # Encode sentences\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity_matrix = cosine_similarity(sentence_embeddings)\n",
    "    \n",
    "    # Find unique sentences\n",
    "    unique_sentences = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        is_unique = True\n",
    "        for j in range(i):\n",
    "            if i != j and similarity_matrix[i][j] > similarity_threshold:\n",
    "                is_unique = False\n",
    "                break\n",
    "        if is_unique and sentence.strip():\n",
    "            unique_sentences.append(sentence)\n",
    "    \n",
    "    # Join unique sentences\n",
    "    return ' '.join(unique_sentences)\n",
    "\n",
    "def format_description(description_text):\n",
    "    sections = description_text.split('\\n\\n')\n",
    "    formatted_sections = []\n",
    "    for section in sections:\n",
    "        if ':' in section:\n",
    "            title, content = section.split(':', 1)\n",
    "            formatted_sections.append(f\"{title.upper()}:\\n{content.strip()}\")\n",
    "        else:\n",
    "            formatted_sections.append(section)\n",
    "    return '\\n\\n'.join(formatted_sections)\n",
    "\n",
    "def assemble_patent(title, field, summary, claims, description, abstract):\n",
    "    return f\"\"\"\n",
    "{title.upper()}\n",
    "\n",
    "BACKGROUND\n",
    "Field: {field}\n",
    "\n",
    "SUMMARY\n",
    "{summary}\n",
    "\n",
    "ABSTRACT\n",
    "\n",
    "{abstract}\n",
    "\n",
    "CLAIMS\n",
    "\n",
    "{claims}\n",
    "\n",
    "DESCRIPTION\n",
    "\n",
    "{description}\n",
    "\"\"\"\n",
    "\n",
    "new_input_data = {\n",
    "    'related_art': \"Image recognition technology is commonly used in security systems to identify faces and objects.\",\n",
    "    'problem_statement': \"Current AI-based image recognition systems are prone to false positives and struggle in low-light conditions, compromising security.\",\n",
    "    'field': \"Artificial intelligence and computer vision\",\n",
    "    'drawings': \"Illustrations of the camera sensors and AI processing unit are attached.\",\n",
    "    'additional_details': \"The system includes infrared sensors and a new AI algorithm that enhances recognition accuracy in low-light environments.\"\n",
    "}\n",
    "\n",
    "input_text = f\"Related Art: {new_input_data['related_art']}\\nProblem Statement: {new_input_data['problem_statement']}\\nField: {new_input_data['field']}\\nDrawings: {new_input_data['drawings']}\\nAdditional Details: {new_input_data['additional_details']}\"\n",
    "\n",
    "# Token limits for different sections\n",
    "token_limits = {\n",
    "    'Title': 30,\n",
    "    'Field': 50,\n",
    "    'Summary': 500,\n",
    "    'Abstract': 250,\n",
    "    'Claims': 1500,\n",
    "    'Description': 7500\n",
    "}\n",
    "\n",
    "# Instructions for each section\n",
    "title_instruction = \"Generate a concise, technical title for the patent, no more than 15 words long.\"\n",
    "\n",
    "field_instruction = \"Generate 1 or 2 sentences describing the field of the invention based on the preamble(s) of the Patent Claims.\"\n",
    "\n",
    "summary_instruction = \"Generate a summary of the invention, reciting all the features of the Patent Claims.\"\n",
    "\n",
    "abstract_instruction = \"\"\"Generate a one-paragraph patent abstract (150-250 words) that includes:\n",
    "1. The field of the invention\n",
    "2. A brief summary of the problem solved\n",
    "3. A high-level description of the invention\n",
    "4. The primary advantage or improvement offered by the invention.\n",
    "\"\"\"\n",
    "\n",
    "claims_instruction = \"\"\"Generate a set of patent claims for the invention using the following structure:\n",
    "\n",
    "1. Independent Claim (1 claim):\n",
    "   - Broadly describe the core invention\n",
    "   - Include all essential elements mentioned in the input\n",
    "   - Format: \"A [type of invention], comprising: [list of key components]; and [key function or purpose].\"\n",
    "\n",
    "2. Dependent Claims - Components (3-4 claims):\n",
    "   - Add specific details about individual components\n",
    "   - Each claim should focus on a different component\n",
    "   - Format: \"The [invention] of claim 1, wherein [specific component] [has a specific feature or function].\"\n",
    "\n",
    "3. Dependent Claims - Functions (3-4 claims):\n",
    "   - Describe specific functions or operations of the invention\n",
    "   - Each claim should focus on a different function\n",
    "   - Format: \"The [invention] of claim 1, wherein [the invention or a component] is configured to [perform a specific function].\"\n",
    "\n",
    "4. Dependent Claims - Configurations (2-3 claims):\n",
    "   - Describe different configurations or arrangements of components\n",
    "   - Format: \"The [invention] of claim 1, further comprising [additional component or arrangement].\"\n",
    "\n",
    "5. Method Claim (1 claim):\n",
    "   - Describe the process of using the invention\n",
    "   - Include key steps that reflect the invention's operation\n",
    "   - Format: \"A method of [using/operating] the [invention] of claim 1, comprising: [list of key steps].\"\n",
    "\n",
    "6. Dependent Method Claims (2-3 claims):\n",
    "   - Add specific details to the method claim\n",
    "   - Format: \"The method of claim [method claim number], further comprising [additional step or detail].\"\n",
    "\n",
    "Ensure each claim is a single sentence. Number claims consecutively. Avoid any repetition in claim content or wording.\n",
    "Aim for 12-15 total claims. Make sure all claims are relevant to the invention described in the input.\"\"\"\n",
    "\n",
    "\n",
    "description_instruction = \"\"\"Generate a detailed patent description including the following sections:\n",
    "1. FIELD OF THE INVENTION (1-2 paragraphs)\n",
    "2. BACKGROUND OF THE INVENTION (2-3 paragraphs)\n",
    "3. SUMMARY OF THE INVENTION (2-3 paragraphs)\n",
    "4. BRIEF DESCRIPTION OF THE DRAWINGS (1-2 paragraphs)\n",
    "5. DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS (4-5 paragraphs)\n",
    "\n",
    "Use appropriate headings for each section. Provide technical details, examples, and references to the drawings. \n",
    "For the DETAILED DESCRIPTION section:\n",
    "- Describe the components of the invention in detail\n",
    "- Explain how these components interact\n",
    "- Provide at least one specific example of how the invention operates\n",
    "- Discuss potential variations or alternative embodiments\n",
    "Aim for a total description length of at least 1000 words.  Avoid any repetition in content or wording. I don't want repititions in the generated text.\"\"\"\n",
    "\n",
    "\n",
    "# Generate each section\n",
    "title = generate_patent_section(title_instruction, input_text, token_limits['Title'])\n",
    "field = generate_patent_section(field_instruction, input_text, token_limits['Field'])\n",
    "summary = generate_patent_section(summary_instruction, input_text, token_limits['Summary'])\n",
    "abstract = generate_patent_section(abstract_instruction, input_text, token_limits['Abstract'])\n",
    "claims = generate_patent_section(claims_instruction, input_text, token_limits['Claims'])\n",
    "description = generate_patent_section(description_instruction, input_text, token_limits['Description'])\n",
    "# Post-process description\n",
    "description = remove_repetitive_sentences(description)\n",
    "\n",
    "# Post-process claims\n",
    "claims = format_claims(claims)\n",
    "# In the generate_patent function, add this line after generating claims:\n",
    "claims = remove_duplicate_claims(claims)\n",
    "# Post-process claims\n",
    "claims = remove_repetitive_sentences(claims)\n",
    "\n",
    "# Assemble the final patent\n",
    "generated_patent = assemble_patent(title, field, summary, claims, description, abstract)\n",
    "\n",
    "# Print the results\n",
    "print(generated_patent)\n",
    "\n",
    "# Optionally, save the generated patent to a file\n",
    "with open(\"generated_patent.txt\", \"w\") as f:\n",
    "    f.write(generated_patent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a24c5b-9494-458e-93ff-649dafcc9734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpllm_newenv",
   "language": "python",
   "name": "nlpllm_newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
