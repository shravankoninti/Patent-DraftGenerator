{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72eb95d7-77b6-42c2-a95d-6222b11bf646",
   "metadata": {},
   "source": [
    "## This code is used for patent draft inference on 10 sample patents (These patents already existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afedc8e4-f96b-4284-97e5-e31e5a4a2d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>claims</th>\n",
       "      <th>description</th>\n",
       "      <th>related_art</th>\n",
       "      <th>problem_statement</th>\n",
       "      <th>field</th>\n",
       "      <th>drawings</th>\n",
       "      <th>additional_details</th>\n",
       "      <th>cleaned_related_art</th>\n",
       "      <th>cleaned_problem_statement</th>\n",
       "      <th>cleaned_field</th>\n",
       "      <th>cleaned_drawings</th>\n",
       "      <th>cleaned_additional_details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-11114351-B2</td>\n",
       "      <td>Dummy element and method of examining defect o...</td>\n",
       "      <td>A dummy element includes: a semiconductor subs...</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A dummy...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION \\n     ...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>A dummy element includes: a semiconductor subs...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION \\n     ...</td>\n",
       "      <td>Dummy element and method of examining defect o...</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A dummy...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION \\n     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US-10946109-B2</td>\n",
       "      <td>Polymer-type fluorescent molecule probe</td>\n",
       "      <td>The present invention provides a fluorescent m...</td>\n",
       "      <td>The invention claimed is: \\n     \\n       1. A...</td>\n",
       "      <td>TECHNICAL FIELD \\n     The present application...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>The present invention provides a fluorescent m...</td>\n",
       "      <td>TECHNICAL FIELD \\n     The present application...</td>\n",
       "      <td>Polymer-type fluorescent molecule probe TECHNI...</td>\n",
       "      <td>The invention claimed is: \\n     \\n       1. A...</td>\n",
       "      <td>TECHNICAL FIELD \\n     The present application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US-11112260-B2</td>\n",
       "      <td>Geospatial navigation methods and systems for ...</td>\n",
       "      <td>An exemplary geospatial navigation system defi...</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A metho...</td>\n",
       "      <td>BACKGROUND INFORMATION \\n     Use of mobile na...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>An exemplary geospatial navigation system defi...</td>\n",
       "      <td>BACKGROUND INFORMATION \\n     Use of mobile na...</td>\n",
       "      <td>Geospatial navigation methods and systems for ...</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A metho...</td>\n",
       "      <td>BACKGROUND INFORMATION \\n     Use of mobile na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US-10940384-B2</td>\n",
       "      <td>Inciting user action for motion sensor calibra...</td>\n",
       "      <td>In a method of motion sensor calibration, a mo...</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A metho...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION—PROVISI...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>In a method of motion sensor calibration, a mo...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION—PROVISI...</td>\n",
       "      <td>Inciting user action for motion sensor calibra...</td>\n",
       "      <td>What is claimed is: \\n     \\n       1. A metho...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION—PROVISI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US-2021298305-A1</td>\n",
       "      <td>Use of a difluoro-(2-hydroxypropyl)pyridine co...</td>\n",
       "      <td>The present disclosure is related to the field...</td>\n",
       "      <td>What is claimed is: \\n     \\n         1 . A me...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION(S) \\n  ...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>\\n    Based on the following patent informatio...</td>\n",
       "      <td>The present disclosure is related to the field...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION(S) \\n  ...</td>\n",
       "      <td>Use of a difluoro-(2-hydroxypropyl)pyridine co...</td>\n",
       "      <td>What is claimed is: \\n     \\n         1. A met...</td>\n",
       "      <td>CROSS-REFERENCE TO RELATED APPLICATION(S) \\n  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publication_number                                              title  \\\n",
       "0     US-11114351-B2  Dummy element and method of examining defect o...   \n",
       "1     US-10946109-B2            Polymer-type fluorescent molecule probe   \n",
       "2     US-11112260-B2  Geospatial navigation methods and systems for ...   \n",
       "3     US-10940384-B2  Inciting user action for motion sensor calibra...   \n",
       "4   US-2021298305-A1  Use of a difluoro-(2-hydroxypropyl)pyridine co...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  A dummy element includes: a semiconductor subs...   \n",
       "1  The present invention provides a fluorescent m...   \n",
       "2  An exemplary geospatial navigation system defi...   \n",
       "3  In a method of motion sensor calibration, a mo...   \n",
       "4  The present disclosure is related to the field...   \n",
       "\n",
       "                                              claims  \\\n",
       "0  What is claimed is: \\n     \\n       1. A dummy...   \n",
       "1  The invention claimed is: \\n     \\n       1. A...   \n",
       "2  What is claimed is: \\n     \\n       1. A metho...   \n",
       "3  What is claimed is: \\n     \\n       1. A metho...   \n",
       "4  What is claimed is: \\n     \\n         1 . A me...   \n",
       "\n",
       "                                         description  \\\n",
       "0  CROSS-REFERENCE TO RELATED APPLICATION \\n     ...   \n",
       "1  TECHNICAL FIELD \\n     The present application...   \n",
       "2  BACKGROUND INFORMATION \\n     Use of mobile na...   \n",
       "3  CROSS-REFERENCE TO RELATED APPLICATION—PROVISI...   \n",
       "4  CROSS-REFERENCE TO RELATED APPLICATION(S) \\n  ...   \n",
       "\n",
       "                                         related_art  \\\n",
       "0  \\n    Based on the following patent informatio...   \n",
       "1  \\n    Based on the following patent informatio...   \n",
       "2  \\n    Based on the following patent informatio...   \n",
       "3  \\n    Based on the following patent informatio...   \n",
       "4  \\n    Based on the following patent informatio...   \n",
       "\n",
       "                                   problem_statement  \\\n",
       "0  \\n    Based on the following patent informatio...   \n",
       "1  \\n    Based on the following patent informatio...   \n",
       "2  \\n    Based on the following patent informatio...   \n",
       "3  \\n    Based on the following patent informatio...   \n",
       "4  \\n    Based on the following patent informatio...   \n",
       "\n",
       "                                               field  \\\n",
       "0  \\n    Based on the following patent informatio...   \n",
       "1  \\n    Based on the following patent informatio...   \n",
       "2  \\n    Based on the following patent informatio...   \n",
       "3  \\n    Based on the following patent informatio...   \n",
       "4  \\n    Based on the following patent informatio...   \n",
       "\n",
       "                                            drawings  \\\n",
       "0  \\n    Based on the following patent informatio...   \n",
       "1  \\n    Based on the following patent informatio...   \n",
       "2  \\n    Based on the following patent informatio...   \n",
       "3  \\n    Based on the following patent informatio...   \n",
       "4  \\n    Based on the following patent informatio...   \n",
       "\n",
       "                                  additional_details  \\\n",
       "0  \\n    Based on the following patent informatio...   \n",
       "1  \\n    Based on the following patent informatio...   \n",
       "2  \\n    Based on the following patent informatio...   \n",
       "3  \\n    Based on the following patent informatio...   \n",
       "4  \\n    Based on the following patent informatio...   \n",
       "\n",
       "                                 cleaned_related_art  \\\n",
       "0  A dummy element includes: a semiconductor subs...   \n",
       "1  The present invention provides a fluorescent m...   \n",
       "2  An exemplary geospatial navigation system defi...   \n",
       "3  In a method of motion sensor calibration, a mo...   \n",
       "4  The present disclosure is related to the field...   \n",
       "\n",
       "                           cleaned_problem_statement  \\\n",
       "0  CROSS-REFERENCE TO RELATED APPLICATION \\n     ...   \n",
       "1  TECHNICAL FIELD \\n     The present application...   \n",
       "2  BACKGROUND INFORMATION \\n     Use of mobile na...   \n",
       "3  CROSS-REFERENCE TO RELATED APPLICATION—PROVISI...   \n",
       "4  CROSS-REFERENCE TO RELATED APPLICATION(S) \\n  ...   \n",
       "\n",
       "                                       cleaned_field  \\\n",
       "0  Dummy element and method of examining defect o...   \n",
       "1  Polymer-type fluorescent molecule probe TECHNI...   \n",
       "2  Geospatial navigation methods and systems for ...   \n",
       "3  Inciting user action for motion sensor calibra...   \n",
       "4  Use of a difluoro-(2-hydroxypropyl)pyridine co...   \n",
       "\n",
       "                                    cleaned_drawings  \\\n",
       "0  What is claimed is: \\n     \\n       1. A dummy...   \n",
       "1  The invention claimed is: \\n     \\n       1. A...   \n",
       "2  What is claimed is: \\n     \\n       1. A metho...   \n",
       "3  What is claimed is: \\n     \\n       1. A metho...   \n",
       "4  What is claimed is: \\n     \\n         1. A met...   \n",
       "\n",
       "                          cleaned_additional_details  \n",
       "0  CROSS-REFERENCE TO RELATED APPLICATION \\n     ...  \n",
       "1  TECHNICAL FIELD \\n     The present application...  \n",
       "2  BACKGROUND INFORMATION \\n     Use of mobile na...  \n",
       "3  CROSS-REFERENCE TO RELATED APPLICATION—PROVISI...  \n",
       "4  CROSS-REFERENCE TO RELATED APPLICATION(S) \\n  ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv('D:/Topcoder/patent_documentation/patent_data_with_cleaned_inputs_phi3_mini.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739c5df3-af41-4b7e-80a0-29e4db5a1374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['publication_number', 'title', 'abstract', 'claims', 'description',\n",
       "       'related_art', 'problem_statement', 'field', 'drawings',\n",
       "       'additional_details', 'cleaned_related_art',\n",
       "       'cleaned_problem_statement', 'cleaned_field', 'cleaned_drawings',\n",
       "       'cleaned_additional_details'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e93167-9a22-41c0-99cd-7088894f896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:660: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed patent 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed patent 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed patent 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed patent 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed patent 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed patent 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed patent 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed patent 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed patent 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Shravan\\anaconda3\\envs\\nlpllm_newenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed patent 10/10\n",
      "\n",
      "Average ROUGE Scores:\n",
      "\n",
      "Title:\n",
      "  rouge1: 0.2191\n",
      "  rouge2: 0.0895\n",
      "  rougeL: 0.1760\n",
      "  rougeLsum: 0.1814\n",
      "\n",
      "Abstract:\n",
      "  rouge1: 0.5725\n",
      "  rouge2: 0.4278\n",
      "  rougeL: 0.4812\n",
      "  rougeLsum: 0.4767\n",
      "\n",
      "Claims:\n",
      "  rouge1: 0.2480\n",
      "  rouge2: 0.1846\n",
      "  rougeL: 0.2112\n",
      "  rougeLsum: 0.2361\n",
      "\n",
      "Description:\n",
      "  rouge1: 0.1042\n",
      "  rouge2: 0.0590\n",
      "  rougeL: 0.0657\n",
      "  rougeLsum: 0.0990\n",
      "\n",
      "Generated patents saved in the 'generated_patents' directory\n",
      "\n",
      "Detailed results saved to 'patent_generation_results.csv'\n",
      "Total execution time in seconds: 10016.22 seconds\n",
      "Total execution time: 166.94 minutes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"beunique/Llama-3.1-8B-bnb-4bit-patent\"\n",
    "# model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "section_times = {}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def generate_patent_section(instruction, input_text, max_tokens=512):\n",
    "    prompt = f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=max_tokens,\n",
    "            temperature=0.7,\n",
    "            top_k=40,\n",
    "            top_p=0.92\n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    response = generated_text.split(\"### Response:\")[-1].strip()\n",
    "    return response\n",
    "\n",
    "\n",
    "def prepare_input(row):\n",
    "    return f\"\"\"Field of Invention: {row['cleaned_field']}\n",
    "Problem to Solve: {row['cleaned_problem_statement']}\n",
    "Related Art: {row['cleaned_related_art']}\n",
    "Key Features: {row['cleaned_additional_details']}\n",
    "Drawings: {row['cleaned_drawings']}\"\"\"\n",
    "\n",
    "\n",
    "def format_claims(claims_text):\n",
    "    formatted_claims = []\n",
    "    seen_claims = set()\n",
    "    for claim in claims_text.split('\\n'):\n",
    "        claim = claim.strip()\n",
    "        if claim and claim.lower() not in seen_claims:\n",
    "            if not claim[0].isdigit():\n",
    "                claim = f\"{len(formatted_claims) + 1}. {claim}\"\n",
    "            formatted_claims.append(claim)\n",
    "            seen_claims.add(claim.lower())\n",
    "    return '\\n'.join(formatted_claims)\n",
    "\n",
    "def remove_duplicate_claims(claims):\n",
    "    unique_claims = []\n",
    "    seen = set()\n",
    "    for claim in claims.split('\\n'):\n",
    "        claim_text = ' '.join(claim.split()[1:])  # Remove the claim number\n",
    "        if claim_text not in seen:\n",
    "            unique_claims.append(claim)\n",
    "            seen.add(claim_text)\n",
    "    return '\\n'.join(unique_claims)\n",
    "\n",
    "\n",
    "def remove_repetitive_sentences(text, similarity_threshold=0.8):\n",
    "    # Load a pre-trained sentence transformer model\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    \n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    \n",
    "    # Encode sentences\n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity_matrix = cosine_similarity(sentence_embeddings)\n",
    "    \n",
    "    # Find unique sentences\n",
    "    unique_sentences = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        is_unique = True\n",
    "        for j in range(i):\n",
    "            if i != j and similarity_matrix[i][j] > similarity_threshold:\n",
    "                is_unique = False\n",
    "                break\n",
    "        if is_unique and sentence.strip():\n",
    "            unique_sentences.append(sentence)\n",
    "    \n",
    "    # Join unique sentences\n",
    "    return ' '.join(unique_sentences)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def assemble_patent(title, field, summary, claims, description, abstract):\n",
    "    return f\"\"\"\n",
    "{title.upper()}\n",
    "\n",
    "BACKGROUND\n",
    "Field: {field}\n",
    "\n",
    "SUMMARY\n",
    "{summary}\n",
    "\n",
    "ABSTRACT\n",
    "\n",
    "{abstract}\n",
    "\n",
    "CLAIMS\n",
    "\n",
    "{claims}\n",
    "\n",
    "DESCRIPTION\n",
    "\n",
    "{description}\n",
    "\"\"\"\n",
    "\n",
    "# Instructions for each section\n",
    "title_instruction = \"Generate a concise, technical title for the patent, no more than 15 words long.\"\n",
    "field_instruction = \"Generate 1 or 2 sentences describing the field of the invention based on the preamble(s) of the Patent Claims.\"\n",
    "\n",
    "summary_instruction = \"Generate a summary of the invention, reciting all the features of the Patent Claims.\"\n",
    "\n",
    "abstract_instruction = \"\"\"Generate a one-paragraph patent abstract (150-250 words) that includes:\n",
    "1. The field of the invention\n",
    "2. A brief summary of the problem solved\n",
    "3. A high-level description of the invention\n",
    "4. The primary advantage or improvement offered by the invention\"\"\"\n",
    "\n",
    "claims_instruction = \"\"\"Generate a set of diverse patent claims for the invention using the following structure:\n",
    "\n",
    "1. Independent Claim (1 claim):\n",
    "   - Broadly describe the core invention\n",
    "   - Include all essential elements mentioned in the input\n",
    "   - Format: \"A [type of invention], comprising: [list of key components]; and [key function or purpose].\"\n",
    "\n",
    "2. Dependent Claims (8-10 claims total):\n",
    "   - Each claim must add a unique, non-repetitive feature or limitation\n",
    "   - Focus on different aspects: components, functions, configurations, materials, etc.\n",
    "   - Format: \"The [invention] of claim [X], wherein/further comprising [new, unique feature].\"\n",
    "\n",
    "3. Method Claim (1 claim):\n",
    "   - Describe the process of using the invention\n",
    "   - Include key steps that reflect the invention's operation\n",
    "   - Format: \"A method of [using/operating] the [invention] of claim 1, comprising: [list of key steps].\"\n",
    "\n",
    "4. Dependent Method Claims (1-2 claims):\n",
    "   - Add specific, non-repetitive details to the method claim\n",
    "   - Format: \"The method of claim [X], further comprising [additional unique step or detail].\"\n",
    "\n",
    "Rules:\n",
    "1. Ensure each claim is a single sentence.\n",
    "2. Number claims consecutively.\n",
    "3. STRICTLY AVOID ANY REPETITION in claim content or wording.If you don't follow this I will be penalized.\n",
    "4. Each claim must introduce a new, unique aspect of the invention.\n",
    "5. Limit to a maximum of 10 claims.\n",
    "6. If you can't generate a new, unique claim, stop generating claims.\n",
    "\n",
    "Make sure all claims are relevant to the invention described in the input.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "description_instruction = \"\"\"Generate a detailed patent description including the following sections:\n",
    "1. FIELD OF THE INVENTION (1-2 paragraphs)\n",
    "2. BACKGROUND OF THE INVENTION (2-3 paragraphs)\n",
    "3. SUMMARY OF THE INVENTION (2-3 paragraphs)\n",
    "4. BRIEF DESCRIPTION OF THE DRAWINGS (1-2 paragraphs)\n",
    "5. DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS (4-5 paragraphs)\n",
    "\n",
    "Use appropriate headings for each section. Provide technical details, examples, and references to the drawings. \n",
    "For the DETAILED DESCRIPTION section:\n",
    "- Describe the components of the invention in detail\n",
    "- Explain how these components interact\n",
    "- Provide at least one specific example of how the invention operates\n",
    "- Discuss potential variations or alternative embodiments\n",
    "- 3. STRICTLY AVOID ANY REPETITION in claim content or wording. If you don't follow this I will be penalized.\n",
    "Aim for a total description length of at least 1000 words.\"\"\"\n",
    "\n",
    "# Token limits for different sections\n",
    "token_limits = {\n",
    "    'Title': 30,\n",
    "    'Field': 50,\n",
    "    'Summary': 500,\n",
    "    'Abstract': 250,\n",
    "    'Claims': 1500,\n",
    "    'Description': 7500\n",
    "}\n",
    "\n",
    "def generate_patent(input_text):\n",
    "    title = generate_patent_section(title_instruction, input_text, token_limits['Title'])\n",
    "    field = generate_patent_section(field_instruction, input_text, token_limits['Field'])\n",
    "    abstract = generate_patent_section(abstract_instruction, input_text, token_limits['Abstract'])\n",
    "    claims = generate_patent_section(claims_instruction, input_text, token_limits['Claims'])\n",
    "    description = generate_patent_section(description_instruction, input_text, token_limits['Description'])\n",
    "    # Post-process description\n",
    "    description = remove_repetitive_sentences(description)\n",
    "    \n",
    "    claims = format_claims(claims)\n",
    "    # In the generate_patent function, add this line after generating claims:\n",
    "    claims = remove_duplicate_claims(claims)\n",
    "    # Post-process claims\n",
    "    claims = remove_repetitive_sentences(claims)\n",
    "    summary = generate_patent_section(summary_instruction, input_text, token_limits['Summary'])\n",
    "    return assemble_patent(title, field, summary, claims, description, abstract)\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv('D:/Topcoder/patent_documentation/patent_data_with_cleaned_inputs_phi3_mini.csv')\n",
    "test_df = test_df.head(10)\n",
    "\n",
    "# Prepare input text for each row\n",
    "test_df['input_text'] = test_df.apply(prepare_input, axis=1)\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "# Function to calculate ROUGE scores\n",
    "def calculate_rouge_scores(pred, ref):\n",
    "    return rouge.compute(predictions=[pred], references=[ref], use_stemmer=True)\n",
    "\n",
    "\n",
    "# Create a directory to store the generated patents\n",
    "os.makedirs('generated_patents', exist_ok=True)\n",
    "\n",
    "# Evaluate on the entire test set\n",
    "all_rouge_scores = []\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    input_text = row['input_text']\n",
    "    generated_patent = generate_patent(input_text)\n",
    "    \n",
    "    # Save the generated patent to a text file\n",
    "    with open(f'generated_patents/patent_{index+1}.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(generated_patent)\n",
    "    \n",
    "    # Calculate ROUGE scores for each section\n",
    "    title_scores = calculate_rouge_scores(generated_patent.split('\\n\\n')[0], row['title'])\n",
    "    abstract_scores = calculate_rouge_scores(generated_patent.split('ABSTRACT\\n\\n')[1].split('CLAIMS')[0], row['abstract'])\n",
    "    claims_scores = calculate_rouge_scores(generated_patent.split('CLAIMS\\n\\n')[1].split('DESCRIPTION')[0], row['claims'])\n",
    "    description_scores = calculate_rouge_scores(generated_patent.split('DESCRIPTION\\n\\n')[1], row['description'])\n",
    "    \n",
    "    # Combine scores\n",
    "    combined_scores = {\n",
    "        'title': title_scores,\n",
    "        'abstract': abstract_scores,\n",
    "        'claims': claims_scores,\n",
    "        'description': description_scores\n",
    "    }\n",
    "    \n",
    "    all_rouge_scores.append(combined_scores)\n",
    "    \n",
    "    print(f\"Processed patent {index + 1}/{len(test_df)}\")\n",
    "\n",
    "# Calculate average ROUGE scores\n",
    "avg_rouge_scores = {\n",
    "    section: {metric: sum(score[section][metric] for score in all_rouge_scores) / len(all_rouge_scores) \n",
    "              for metric in all_rouge_scores[0][section]}\n",
    "    for section in ['title', 'abstract', 'claims', 'description']\n",
    "}\n",
    "\n",
    "# Print average ROUGE scores\n",
    "print(\"\\nAverage ROUGE Scores:\")\n",
    "for section, scores in avg_rouge_scores.items():\n",
    "    print(f\"\\n{section.capitalize()}:\")\n",
    "    for metric, value in scores.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Save the results to a CSV file\n",
    "print(f\"\\nGenerated patents saved in the 'generated_patents' directory\")\n",
    "results_df = pd.DataFrame(all_rouge_scores)\n",
    "results_df.to_csv('patent_generation_results.csv', index=False)\n",
    "print(\"\\nDetailed results saved to 'patent_generation_results.csv'\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total execution time in seconds: {total_time:.2f} seconds\")\n",
    "total_time_minutes = total_time / 60\n",
    "print(f\"Total execution time: {total_time_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6489cd98-7230-4854-9056-682d98fc8d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpllm_newenv",
   "language": "python",
   "name": "nlpllm_newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
